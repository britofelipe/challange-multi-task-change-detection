{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b6fea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fe6323",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_type_map = {'Demolition': 0, 'Road': 1, 'Residential': 2, 'Commercial': 3, 'Industrial': 4,\n",
    "       'Mega Projects': 5}\n",
    "\n",
    "## Read csvs\n",
    "print(\"Reading data...\")\n",
    "train_df = gpd.read_file('train.geojson').head(100)\n",
    "test_df = gpd.read_file('test.geojson').head(100)\n",
    "print(\"Data read successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec8933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d20e064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING\n",
    "print(\"Feature Engineering...\")\n",
    "\n",
    "# 1. Geometry-based features\n",
    "train_df['area'] = train_df.geometry.area\n",
    "train_df['perimeter'] = train_df.geometry.length\n",
    "train_df['compactness'] = train_df['area'] / (train_df['perimeter']**2 + 1e-6)\n",
    "\n",
    "test_df['area'] = test_df.geometry.area\n",
    "test_df['perimeter'] = test_df.geometry.length\n",
    "test_df['compactness'] = test_df['area'] / (test_df['perimeter']**2 + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbc8dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Date-based features\n",
    "date_cols = ['date1', 'date2', 'date3', 'date4', 'date5']\n",
    "if all(col in train_df.columns for col in date_cols):\n",
    "    for col in date_cols:\n",
    "        train_df[col] = pd.to_datetime(train_df[col])\n",
    "        test_df[col] = pd.to_datetime(test_df[col])\n",
    "    for i in range(len(date_cols) - 1):\n",
    "        diff_col = f'days_diff_{i+1}_{i+2}'\n",
    "        train_df[diff_col] = (train_df[date_cols[i+1]] - train_df[date_cols[i]]).dt.days\n",
    "        test_df[diff_col] = (test_df[date_cols[i+1]] - test_df[date_cols[i]]).dt.days\n",
    "else:\n",
    "    print(\"Date columns not found, skipping date-based features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb339e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Categorical features\n",
    "categorical_features = []\n",
    "if 'urban_type' in train_df.columns:\n",
    "    categorical_features.append('urban_type')\n",
    "if 'geography_type' in train_df.columns:\n",
    "    categorical_features.append('geography_type')\n",
    "\n",
    "if categorical_features:\n",
    "    encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    train_cat = encoder.fit_transform(train_df[categorical_features])\n",
    "    test_cat = encoder.transform(test_df[categorical_features])\n",
    "else:\n",
    "    train_cat = np.empty((len(train_df), 0))\n",
    "    test_cat = np.empty((len(test_df), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed391100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Combine numerical features\n",
    "num_features = ['area', 'perimeter', 'compactness']\n",
    "date_diff_cols = [col for col in train_df.columns if col.startswith('days_diff_')]\n",
    "num_features.extend(date_diff_cols)\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "train_num = imputer.fit_transform(train_df[num_features])\n",
    "test_num = imputer.transform(test_df[num_features])\n",
    "\n",
    "train_x = np.hstack([train_num, train_cat])\n",
    "test_x = np.hstack([test_num, test_cat])\n",
    "\n",
    "train_y = train_df['change_type'].apply(lambda x: change_type_map[x]).values\n",
    "\n",
    "print(\"Feature engineering completed. Feature shapes:\")\n",
    "print(\"Train features:\", train_x.shape)\n",
    "print(\"Test features:\", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e75630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIMENSIONALITY REDUCTION\n",
    "scaler = StandardScaler()\n",
    "train_x_scaled = scaler.fit_transform(train_x)\n",
    "test_x_scaled = scaler.transform(test_x)\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "train_x_pca = pca.fit_transform(train_x_scaled)\n",
    "test_x_pca = pca.transform(test_x_scaled)\n",
    "\n",
    "print(f\"Reduction from {train_x_scaled.shape[1]} to {train_x_pca.shape[1]} dimensions due to PCA\")\n",
    "\n",
    "# Separate training data\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_x_pca, train_y, test_size=0.2, random_state=42, stratify=train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8129d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    \"SVM\": SVC(kernel=\"rbf\", probability=True),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=500, n_jobs=-1),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\", n_jobs=-1)\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_score = 0\n",
    "model_results = {}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=\"f1_macro\", n_jobs=-1)\n",
    "    mean_score = np.mean(scores)\n",
    "    model_results[name] = mean_score\n",
    "    print(f\"{name} - Mean F1 Score: {mean_score:.4f}\")\n",
    "\n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_model = model\n",
    "\n",
    "print(f\"Best model: {best_model.__class__.__name__} with F1-score: {best_score:.4f}\")\n",
    "best_model.fit(X_train, y_train)\n",
    "pred_y = best_model.predict(test_x_pca)\n",
    "\n",
    "# Save results\n",
    "pred_df = pd.DataFrame(pred_y, columns=['change_type'])\n",
    "pred_df.to_csv(\"submission.csv\", index=True, index_label='Id')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
